---
keywords: fastai
title: Title
nb_path: _notebooks/2023-05-25-stock-predictor.ipynb
layout: notebook
---

<!--
#################################################
### THIS FILE WAS AUTOGENERATED! DO NOT EDIT! ###
#################################################
# file to edit: _notebooks/2023-05-25-stock-predictor.ipynb
-->

<div class="container" id="notebook-container">
        
    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="kn">import</span> <span class="nn">yfinance</span> <span class="k">as</span> <span class="nn">yf</span>

<span class="c1"># Define the ticker symbol</span>
<span class="n">tickerSymbol</span> <span class="o">=</span> <span class="s1">&#39;AAPL&#39;</span>

<span class="c1"># Get data for this ticker</span>
<span class="n">tickerData</span> <span class="o">=</span> <span class="n">yf</span><span class="o">.</span><span class="n">Ticker</span><span class="p">(</span><span class="n">tickerSymbol</span><span class="p">)</span>

<span class="c1"># Get the historical prices for this ticker</span>
<span class="n">tickerDf</span> <span class="o">=</span> <span class="n">tickerData</span><span class="o">.</span><span class="n">history</span><span class="p">(</span><span class="n">period</span><span class="o">=</span><span class="s1">&#39;1d&#39;</span><span class="p">,</span> <span class="n">start</span><span class="o">=</span><span class="s1">&#39;2022-1-1&#39;</span><span class="p">,</span> <span class="n">end</span><span class="o">=</span><span class="s1">&#39;2023-1-25&#39;</span><span class="p">)</span>

<span class="c1"># See your data</span>
<span class="nb">print</span><span class="p">(</span><span class="n">tickerDf</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>                                 Open        High         Low       Close  \
Date                                                                        
2022-01-03 00:00:00-05:00  176.290490  181.296774  176.171534  180.434296   
2022-01-04 00:00:00-05:00  181.048929  181.356243  177.569307  178.144287   
2022-01-05 00:00:00-05:00  178.055086  178.610235  173.128111  173.405685   
2022-01-06 00:00:00-05:00  171.204893  173.782390  170.154072  170.510956   
2022-01-07 00:00:00-05:00  171.393242  172.632420  169.549344  170.679474   
...                               ...         ...         ...         ...   
2023-01-18 00:00:00-05:00  136.422724  138.207519  134.637913  134.817398   
2023-01-19 00:00:00-05:00  133.690681  135.854378  133.381583  134.877228   
2023-01-20 00:00:00-05:00  134.887190  137.619239  133.830270  137.469666   
2023-01-23 00:00:00-05:00  137.718933  142.903846  137.499571  140.700256   
2023-01-24 00:00:00-05:00  139.902580  142.744310  139.892614  142.116135   

                              Volume  Dividends  Stock Splits  
Date                                                           
2022-01-03 00:00:00-05:00  104487900        0.0           0.0  
2022-01-04 00:00:00-05:00   99310400        0.0           0.0  
2022-01-05 00:00:00-05:00   94537600        0.0           0.0  
2022-01-06 00:00:00-05:00   96904000        0.0           0.0  
2022-01-07 00:00:00-05:00   86709100        0.0           0.0  
...                              ...        ...           ...  
2023-01-18 00:00:00-05:00   69672800        0.0           0.0  
2023-01-19 00:00:00-05:00   58280400        0.0           0.0  
2023-01-20 00:00:00-05:00   80223600        0.0           0.0  
2023-01-23 00:00:00-05:00   81760300        0.0           0.0  
2023-01-24 00:00:00-05:00   66435100        0.0           0.0  

[266 rows x 7 columns]
</pre>
</div>
</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">from</span> <span class="nn">sklearn.preprocessing</span> <span class="kn">import</span> <span class="n">MinMaxScaler</span>
<span class="kn">from</span> <span class="nn">tensorflow.keras.models</span> <span class="kn">import</span> <span class="n">Sequential</span>
<span class="kn">from</span> <span class="nn">tensorflow.keras.layers</span> <span class="kn">import</span> <span class="n">LSTM</span><span class="p">,</span> <span class="n">Dense</span>

<span class="c1"># Use only closing price data for simplicity</span>
<span class="n">data</span> <span class="o">=</span> <span class="n">tickerDf</span><span class="p">[</span><span class="s1">&#39;Close&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">values</span>
<span class="n">data</span> <span class="o">=</span> <span class="n">data</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>

<span class="c1"># Scale the data</span>
<span class="n">scaler</span> <span class="o">=</span> <span class="n">MinMaxScaler</span><span class="p">(</span><span class="n">feature_range</span><span class="o">=</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span><span class="mi">1</span><span class="p">))</span>
<span class="n">data</span> <span class="o">=</span> <span class="n">scaler</span><span class="o">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>

<span class="c1"># Define a data preparation function</span>
<span class="k">def</span> <span class="nf">create_dataset</span><span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="n">look_back</span><span class="o">=</span><span class="mi">1</span><span class="p">):</span>
    <span class="n">X</span><span class="p">,</span> <span class="n">Y</span> <span class="o">=</span> <span class="p">[],</span> <span class="p">[]</span>
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">data</span><span class="p">)</span><span class="o">-</span><span class="n">look_back</span><span class="o">-</span><span class="mi">1</span><span class="p">):</span>
        <span class="n">a</span> <span class="o">=</span> <span class="n">data</span><span class="p">[</span><span class="n">i</span><span class="p">:(</span><span class="n">i</span><span class="o">+</span><span class="n">look_back</span><span class="p">),</span> <span class="mi">0</span><span class="p">]</span>
        <span class="n">X</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">a</span><span class="p">)</span>
        <span class="n">Y</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">data</span><span class="p">[</span><span class="n">i</span> <span class="o">+</span> <span class="n">look_back</span><span class="p">,</span> <span class="mi">0</span><span class="p">])</span>
    <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">X</span><span class="p">),</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">Y</span><span class="p">)</span>

<span class="c1"># Prepare the data</span>
<span class="n">look_back</span> <span class="o">=</span> <span class="mi">10</span>
<span class="n">X</span><span class="p">,</span> <span class="n">Y</span> <span class="o">=</span> <span class="n">create_dataset</span><span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="n">look_back</span><span class="p">)</span>

<span class="c1"># Reshape input to be [samples, time steps, features]</span>
<span class="n">X</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="p">(</span><span class="n">X</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="mi">1</span><span class="p">,</span> <span class="n">X</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]))</span>

<span class="c1"># Define the LSTM model</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">Sequential</span><span class="p">()</span>
<span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">LSTM</span><span class="p">(</span><span class="mi">4</span><span class="p">,</span> <span class="n">input_shape</span><span class="o">=</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">look_back</span><span class="p">)))</span>
<span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">Dense</span><span class="p">(</span><span class="mi">1</span><span class="p">))</span>
<span class="n">model</span><span class="o">.</span><span class="n">compile</span><span class="p">(</span><span class="n">loss</span><span class="o">=</span><span class="s1">&#39;mean_squared_error&#39;</span><span class="p">,</span> <span class="n">optimizer</span><span class="o">=</span><span class="s1">&#39;adam&#39;</span><span class="p">)</span>

<span class="c1"># Train the model</span>
<span class="n">model</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">Y</span><span class="p">,</span> <span class="n">epochs</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">verbose</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stderr output_text">
<pre>2023-05-25 12:20:45.675319: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor &#39;gradients/split_2_grad/concat/split_2/split_dim&#39; with dtype int32
	 [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]
2023-05-25 12:20:45.680324: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor &#39;gradients/split_grad/concat/split/split_dim&#39; with dtype int32
	 [[{{node gradients/split_grad/concat/split/split_dim}}]]
2023-05-25 12:20:45.685267: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor &#39;gradients/split_1_grad/concat/split_1/split_dim&#39; with dtype int32
	 [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]
</pre>
</div>
</div>

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>Epoch 1/100
</pre>
</div>
</div>

<div class="output_area">

<div class="output_subarea output_stream output_stderr output_text">
<pre>2023-05-25 12:20:46.476901: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor &#39;gradients/split_2_grad/concat/split_2/split_dim&#39; with dtype int32
	 [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]
2023-05-25 12:20:46.482395: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor &#39;gradients/split_grad/concat/split/split_dim&#39; with dtype int32
	 [[{{node gradients/split_grad/concat/split/split_dim}}]]
2023-05-25 12:20:46.485889: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor &#39;gradients/split_1_grad/concat/split_1/split_dim&#39; with dtype int32
	 [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]
2023-05-25 12:20:48.523382: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor &#39;gradients/split_2_grad/concat/split_2/split_dim&#39; with dtype int32
	 [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]
2023-05-25 12:20:48.530612: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor &#39;gradients/split_grad/concat/split/split_dim&#39; with dtype int32
	 [[{{node gradients/split_grad/concat/split/split_dim}}]]
2023-05-25 12:20:48.535602: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor &#39;gradients/split_1_grad/concat/split_1/split_dim&#39; with dtype int32
	 [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]
</pre>
</div>
</div>

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>255/255 - 5s - loss: 0.1739 - 5s/epoch - 21ms/step
Epoch 2/100
255/255 - 1s - loss: 0.0155 - 915ms/epoch - 4ms/step
Epoch 3/100
255/255 - 1s - loss: 0.0103 - 937ms/epoch - 4ms/step
Epoch 4/100
255/255 - 1s - loss: 0.0076 - 1s/epoch - 5ms/step
Epoch 5/100
255/255 - 1s - loss: 0.0066 - 1s/epoch - 5ms/step
Epoch 6/100
255/255 - 1s - loss: 0.0060 - 1s/epoch - 5ms/step
Epoch 7/100
255/255 - 1s - loss: 0.0059 - 1s/epoch - 4ms/step
Epoch 8/100
255/255 - 1s - loss: 0.0057 - 1s/epoch - 5ms/step
Epoch 9/100
255/255 - 1s - loss: 0.0055 - 1s/epoch - 4ms/step
Epoch 10/100
255/255 - 1s - loss: 0.0053 - 1s/epoch - 5ms/step
Epoch 11/100
255/255 - 1s - loss: 0.0052 - 984ms/epoch - 4ms/step
Epoch 12/100
255/255 - 1s - loss: 0.0052 - 1s/epoch - 5ms/step
Epoch 13/100
255/255 - 1s - loss: 0.0050 - 1s/epoch - 5ms/step
Epoch 14/100
255/255 - 2s - loss: 0.0049 - 2s/epoch - 6ms/step
Epoch 15/100
255/255 - 1s - loss: 0.0051 - 1s/epoch - 4ms/step
Epoch 16/100
</pre>
</div>
</div>

<div class="output_area">

<div class="output_subarea output_text output_error">
<pre>
<span class="ansi-red-fg">---------------------------------------------------------------------------</span>
<span class="ansi-red-fg">KeyboardInterrupt</span>                         Traceback (most recent call last)
<span class="ansi-green-intense-fg ansi-bold">/home/kaylee/vscode/myproject/_notebooks/2023-05-25-stock-predictor.ipynb Cell 2</span> in <span class="ansi-cyan-fg">&lt;cell line: 37&gt;</span><span class="ansi-blue-fg">()</span>
<span class="ansi-green-intense-fg ansi-bold">     &lt;a href=&#39;vscode-notebook-cell://wsl%2Bubuntu/home/kaylee/vscode/myproject/_notebooks/2023-05-25-stock-predictor.ipynb#W1sdnNjb2RlLXJlbW90ZQ%3D%3D?line=33&#39;&gt;34&lt;/a&gt;</span> model.compile(loss=&#39;mean_squared_error&#39;, optimizer=&#39;adam&#39;)
<span class="ansi-green-intense-fg ansi-bold">     &lt;a href=&#39;vscode-notebook-cell://wsl%2Bubuntu/home/kaylee/vscode/myproject/_notebooks/2023-05-25-stock-predictor.ipynb#W1sdnNjb2RlLXJlbW90ZQ%3D%3D?line=35&#39;&gt;36&lt;/a&gt;</span> # Train the model
<span class="ansi-green-fg">---&gt; &lt;a href=&#39;vscode-notebook-cell://wsl%2Bubuntu/home/kaylee/vscode/myproject/_notebooks/2023-05-25-stock-predictor.ipynb#W1sdnNjb2RlLXJlbW90ZQ%3D%3D?line=36&#39;&gt;37&lt;/a&gt;</span> model.fit(X, Y, epochs=100, batch_size=1, verbose=2)

File <span class="ansi-green-fg">~/anaconda3/lib/python3.9/site-packages/keras/utils/traceback_utils.py:65</span>, in <span class="ansi-cyan-fg">filter_traceback.&lt;locals&gt;.error_handler</span><span class="ansi-blue-fg">(*args, **kwargs)</span>
<span class="ansi-green-intense-fg ansi-bold">     63</span> filtered_tb = None
<span class="ansi-green-intense-fg ansi-bold">     64</span> try:
<span class="ansi-green-fg">---&gt; 65</span>     return fn(*args, **kwargs)
<span class="ansi-green-intense-fg ansi-bold">     66</span> except Exception as e:
<span class="ansi-green-intense-fg ansi-bold">     67</span>     filtered_tb = _process_traceback_frames(e.__traceback__)

File <span class="ansi-green-fg">~/anaconda3/lib/python3.9/site-packages/keras/engine/training.py:1685</span>, in <span class="ansi-cyan-fg">Model.fit</span><span class="ansi-blue-fg">(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)</span>
<span class="ansi-green-intense-fg ansi-bold">   1677</span> with tf.profiler.experimental.Trace(
<span class="ansi-green-intense-fg ansi-bold">   1678</span>     &#34;train&#34;,
<span class="ansi-green-intense-fg ansi-bold">   1679</span>     epoch_num=epoch,
<span class="ansi-green-fg">   (...)</span>
<span class="ansi-green-intense-fg ansi-bold">   1682</span>     _r=1,
<span class="ansi-green-intense-fg ansi-bold">   1683</span> ):
<span class="ansi-green-intense-fg ansi-bold">   1684</span>     callbacks.on_train_batch_begin(step)
<span class="ansi-green-fg">-&gt; 1685</span>     tmp_logs = self.train_function(iterator)
<span class="ansi-green-intense-fg ansi-bold">   1686</span>     if data_handler.should_sync:
<span class="ansi-green-intense-fg ansi-bold">   1687</span>         context.async_wait()

File <span class="ansi-green-fg">~/anaconda3/lib/python3.9/site-packages/tensorflow/python/util/traceback_utils.py:150</span>, in <span class="ansi-cyan-fg">filter_traceback.&lt;locals&gt;.error_handler</span><span class="ansi-blue-fg">(*args, **kwargs)</span>
<span class="ansi-green-intense-fg ansi-bold">    148</span> filtered_tb = None
<span class="ansi-green-intense-fg ansi-bold">    149</span> try:
<span class="ansi-green-fg">--&gt; 150</span>   return fn(*args, **kwargs)
<span class="ansi-green-intense-fg ansi-bold">    151</span> except Exception as e:
<span class="ansi-green-intense-fg ansi-bold">    152</span>   filtered_tb = _process_traceback_frames(e.__traceback__)

File <span class="ansi-green-fg">~/anaconda3/lib/python3.9/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:894</span>, in <span class="ansi-cyan-fg">Function.__call__</span><span class="ansi-blue-fg">(self, *args, **kwds)</span>
<span class="ansi-green-intense-fg ansi-bold">    891</span> compiler = &#34;xla&#34; if self._jit_compile else &#34;nonXla&#34;
<span class="ansi-green-intense-fg ansi-bold">    893</span> with OptionalXlaContext(self._jit_compile):
<span class="ansi-green-fg">--&gt; 894</span>   result = self._call(*args, **kwds)
<span class="ansi-green-intense-fg ansi-bold">    896</span> new_tracing_count = self.experimental_get_tracing_count()
<span class="ansi-green-intense-fg ansi-bold">    897</span> without_tracing = (tracing_count == new_tracing_count)

File <span class="ansi-green-fg">~/anaconda3/lib/python3.9/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:926</span>, in <span class="ansi-cyan-fg">Function._call</span><span class="ansi-blue-fg">(self, *args, **kwds)</span>
<span class="ansi-green-intense-fg ansi-bold">    923</span>   self._lock.release()
<span class="ansi-green-intense-fg ansi-bold">    924</span>   # In this case we have created variables on the first call, so we run the
<span class="ansi-green-intense-fg ansi-bold">    925</span>   # defunned version which is guaranteed to never create variables.
<span class="ansi-green-fg">--&gt; 926</span>   return self._no_variable_creation_fn(*args, **kwds)  # pylint: disable=not-callable
<span class="ansi-green-intense-fg ansi-bold">    927</span> elif self._variable_creation_fn is not None:
<span class="ansi-green-intense-fg ansi-bold">    928</span>   # Release the lock early so that multiple threads can perform the call
<span class="ansi-green-intense-fg ansi-bold">    929</span>   # in parallel.
<span class="ansi-green-intense-fg ansi-bold">    930</span>   self._lock.release()

File <span class="ansi-green-fg">~/anaconda3/lib/python3.9/site-packages/tensorflow/python/eager/polymorphic_function/tracing_compiler.py:143</span>, in <span class="ansi-cyan-fg">TracingCompiler.__call__</span><span class="ansi-blue-fg">(self, *args, **kwargs)</span>
<span class="ansi-green-intense-fg ansi-bold">    140</span> with self._lock:
<span class="ansi-green-intense-fg ansi-bold">    141</span>   (concrete_function,
<span class="ansi-green-intense-fg ansi-bold">    142</span>    filtered_flat_args) = self._maybe_define_function(args, kwargs)
<span class="ansi-green-fg">--&gt; 143</span> return concrete_function._call_flat(
<span class="ansi-green-intense-fg ansi-bold">    144</span>     filtered_flat_args, captured_inputs=concrete_function.captured_inputs)

File <span class="ansi-green-fg">~/anaconda3/lib/python3.9/site-packages/tensorflow/python/eager/polymorphic_function/monomorphic_function.py:1757</span>, in <span class="ansi-cyan-fg">ConcreteFunction._call_flat</span><span class="ansi-blue-fg">(self, args, captured_inputs, cancellation_manager)</span>
<span class="ansi-green-intense-fg ansi-bold">   1753</span> possible_gradient_type = gradients_util.PossibleTapeGradientTypes(args)
<span class="ansi-green-intense-fg ansi-bold">   1754</span> if (possible_gradient_type == gradients_util.POSSIBLE_GRADIENT_TYPES_NONE
<span class="ansi-green-intense-fg ansi-bold">   1755</span>     and executing_eagerly):
<span class="ansi-green-intense-fg ansi-bold">   1756</span>   # No tape is watching; skip to running the function.
<span class="ansi-green-fg">-&gt; 1757</span>   return self._build_call_outputs(self._inference_function.call(
<span class="ansi-green-intense-fg ansi-bold">   1758</span>       ctx, args, cancellation_manager=cancellation_manager))
<span class="ansi-green-intense-fg ansi-bold">   1759</span> forward_backward = self._select_forward_and_backward_functions(
<span class="ansi-green-intense-fg ansi-bold">   1760</span>     args,
<span class="ansi-green-intense-fg ansi-bold">   1761</span>     possible_gradient_type,
<span class="ansi-green-intense-fg ansi-bold">   1762</span>     executing_eagerly)
<span class="ansi-green-intense-fg ansi-bold">   1763</span> forward_function, args_with_tangents = forward_backward.forward()

File <span class="ansi-green-fg">~/anaconda3/lib/python3.9/site-packages/tensorflow/python/eager/polymorphic_function/monomorphic_function.py:381</span>, in <span class="ansi-cyan-fg">_EagerDefinedFunction.call</span><span class="ansi-blue-fg">(self, ctx, args, cancellation_manager)</span>
<span class="ansi-green-intense-fg ansi-bold">    379</span> with _InterpolateFunctionError(self):
<span class="ansi-green-intense-fg ansi-bold">    380</span>   if cancellation_manager is None:
<span class="ansi-green-fg">--&gt; 381</span>     outputs = execute.execute(
<span class="ansi-green-intense-fg ansi-bold">    382</span>         str(self.signature.name),
<span class="ansi-green-intense-fg ansi-bold">    383</span>         num_outputs=self._num_outputs,
<span class="ansi-green-intense-fg ansi-bold">    384</span>         inputs=args,
<span class="ansi-green-intense-fg ansi-bold">    385</span>         attrs=attrs,
<span class="ansi-green-intense-fg ansi-bold">    386</span>         ctx=ctx)
<span class="ansi-green-intense-fg ansi-bold">    387</span>   else:
<span class="ansi-green-intense-fg ansi-bold">    388</span>     outputs = execute.execute_with_cancellation(
<span class="ansi-green-intense-fg ansi-bold">    389</span>         str(self.signature.name),
<span class="ansi-green-intense-fg ansi-bold">    390</span>         num_outputs=self._num_outputs,
<span class="ansi-green-fg">   (...)</span>
<span class="ansi-green-intense-fg ansi-bold">    393</span>         ctx=ctx,
<span class="ansi-green-intense-fg ansi-bold">    394</span>         cancellation_manager=cancellation_manager)

File <span class="ansi-green-fg">~/anaconda3/lib/python3.9/site-packages/tensorflow/python/eager/execute.py:52</span>, in <span class="ansi-cyan-fg">quick_execute</span><span class="ansi-blue-fg">(op_name, num_outputs, inputs, attrs, ctx, name)</span>
<span class="ansi-green-intense-fg ansi-bold">     50</span> try:
<span class="ansi-green-intense-fg ansi-bold">     51</span>   ctx.ensure_initialized()
<span class="ansi-green-fg">---&gt; 52</span>   tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,
<span class="ansi-green-intense-fg ansi-bold">     53</span>                                       inputs, attrs, num_outputs)
<span class="ansi-green-intense-fg ansi-bold">     54</span> except core._NotOkStatusException as e:
<span class="ansi-green-intense-fg ansi-bold">     55</span>   if name is not None:

<span class="ansi-red-fg">KeyboardInterrupt</span>: </pre>
</div>
</div>

</div>
</div>

</div>
    {% endraw %}

</div>
 

